// services/bq-integration.js - COMPLETE UPDATED VERSION: Fallback Cleanup Strategy
const { BigQuery } = require('@google-cloud/bigquery');

class BigQueryIntegrationService {
    constructor() {
        this.bigquery = new BigQuery({
            projectId: process.env.GOOGLE_CLOUD_PROJECT_ID,
        });
        
        // Configuration for task assessment data
        this.config = {
            sourceTable: 'rax-landing-qa.snow_ods.task_assessment_detail',
            tempDataset: 'temp_validation_tables',
            tempTablePrefix: 'json_temp_'
        };
        
        console.log('üîó BigQuery Integration Service initialized - FALLBACK CLEANUP VERSION');
        console.log(`üìä Project: ${process.env.GOOGLE_CLOUD_PROJECT_ID}`);
        console.log(`üéØ Source Table: ${this.config.sourceTable}`);
    }

    /**
     * ENHANCED: Clean field name for BigQuery compatibility
     */
    cleanFieldName(fieldName) {
        return fieldName
            .replace(/[^a-zA-Z0-9_]/g, '_')  // Replace invalid chars with underscore
            .replace(/^[0-9]/, '_$&')        // Prefix numbers with underscore
            .substring(0, 128)               // Limit length to 128 chars
            .toLowerCase();                  // Convert to lowercase for consistency
    }

    /**
     * ENHANCED: Clean and validate data value for BigQuery
     */
    cleanDataValue(value, fieldName) {
        if (value === null || value === undefined) {
            return null;
        }

        // Convert to string and clean
        let cleanValue = String(value).trim();
        
        // Handle very long values (BigQuery STRING limit)
        if (cleanValue.length > 50000) {
            console.warn(`‚ö†Ô∏è Truncating long value for field ${fieldName}: ${cleanValue.length} chars ‚Üí 50000 chars`);
            cleanValue = cleanValue.substring(0, 50000) + '... [TRUNCATED]';
        }

        // Clean problematic characters
        cleanValue = cleanValue
            .replace(/\0/g, '')              // Remove null characters
            .replace(/\r\n/g, '\n')          // Normalize line endings
            .replace(/\r/g, '\n')            // Convert CR to LF
            .replace(/[\x00-\x1F\x7F]/g, ' '); // Replace control characters with spaces

        return cleanValue;
    }

    /**
     * Test BigQuery connection
     */
    async testConnection() {
        try {
            console.log('üß™ Testing BigQuery connection...');
            
            const query = `SELECT 1 as test_connection`;
            const [rows] = await this.bigquery.query(query);
            
            console.log('‚úÖ BigQuery connection successful');
            return { success: true, message: 'Connection established' };
            
        } catch (error) {
            console.error('‚ùå BigQuery connection failed:', error.message);
            throw error;
        }
    }

    /**
     * Test access to source table and get basic info
     */
    async testSourceTableAccess() {
        try {
            console.log('üîç Testing access to source table...');
            console.log(`üìã Table: ${this.config.sourceTable}`);
            
            const countQuery = `
                SELECT COUNT(*) as record_count 
                FROM \`${this.config.sourceTable}\`
                LIMIT 1
            `;
            
            const [countResults] = await this.bigquery.query(countQuery);
            const recordCount = countResults[0].record_count;
            
            console.log(`‚úÖ Source table access successful`);
            console.log(`üìä Record count: ${recordCount}`);
            
            return { 
                success: true, 
                message: 'Source table accessible',
                recordCount: parseInt(recordCount),
                tableName: this.config.sourceTable
            };
            
        } catch (error) {
            console.error('‚ùå Source table access failed:', error.message);
            
            if (error.message.includes('not found')) {
                throw new Error(`Table not found: ${this.config.sourceTable}. Please verify the table exists.`);
            } else if (error.message.includes('permission') || error.message.includes('Access Denied')) {
                throw new Error(`Permission denied accessing: ${this.config.sourceTable}. Please check your BigQuery permissions.`);
            } else {
                throw new Error(`Failed to access source table: ${error.message}`);
            }
        }
    }

    /**
     * Get schema information using LIMIT 0 approach (works cross-project)
     */
    async getSourceTableSchema() {
        try {
            console.log('üìã Getting source table schema...');
            
            const schemaQuery = `SELECT * FROM \`${this.config.sourceTable}\` LIMIT 0`;
            const [schemaResults] = await this.bigquery.query(schemaQuery);
            
            const job = this.bigquery.job(schemaResults.jobReference?.jobId);
            const [jobMetadata] = await job.getMetadata();
            const schema = jobMetadata.configuration.query.destinationTable ? 
                jobMetadata.statistics.query.schema?.fields || [] :
                [];

            let fieldNames = [];
            if (schemaResults.length === 0 && schemaResults._config) {
                fieldNames = Object.keys(schemaResults[0] || {});
            }

            if (schema.length === 0 && fieldNames.length === 0) {
                console.log('üìã Using fallback column detection...');
                
                const columnQuery = `
                    SELECT column_name, data_type 
                    FROM \`${this.config.sourceTable.split('.')[0]}\`.\`${this.config.sourceTable.split('.')[1]}\`.INFORMATION_SCHEMA.COLUMNS
                    WHERE table_name = '${this.config.sourceTable.split('.')[2]}'
                    ORDER BY ordinal_position
                `;
                
                try {
                    const [columnResults] = await this.bigquery.query(columnQuery);
                    console.log(`‚úÖ Schema retrieved via fallback: ${columnResults.length} fields found`);
                    
                    return {
                        success: true,
                        message: 'Schema retrieved successfully (via fallback)',
                        totalFields: columnResults.length,
                        schema: columnResults,
                        keyFields: columnResults.filter(field => 
                            ['task_sys_id', 'task_number', 'task_priority', 'task_state', 'asmtins_state'].includes(field.column_name)
                        ),
                        tableName: this.config.sourceTable
                    };
                    
                } catch (fallbackError) {
                    console.error('‚ùå Fallback schema query failed:', fallbackError.message);
                    
                    return {
                        success: true,
                        message: 'Schema access limited',
                        totalFields: 'Unknown',
                        schema: [],
                        keyFields: [
                            { column_name: 'task_sys_id', data_type: 'STRING' },
                            { column_name: 'task_number', data_type: 'STRING' },
                            { column_name: 'task_priority', data_type: 'STRING' },
                            { column_name: 'task_state', data_type: 'STRING' },
                            { column_name: 'asmtins_state', data_type: 'STRING' }
                        ],
                        tableName: this.config.sourceTable,
                        note: 'Cross-project schema access limited'
                    };
                }
            }
            
            return {
                success: true,
                message: 'Schema retrieved successfully',
                totalFields: schema.length || fieldNames.length,
                schema: schema.length > 0 ? schema : fieldNames,
                keyFields: [],
                tableName: this.config.sourceTable
            };
            
        } catch (error) {
            console.error('‚ùå Schema retrieval failed:', error.message);
            
            return {
                success: true,
                message: 'Schema access limited',
                totalFields: 'Cross-project access limited',
                schema: [],
                keyFields: [
                    { column_name: 'task_sys_id', data_type: 'STRING' },
                    { column_name: 'task_number', data_type: 'STRING' },
                    { column_name: 'task_priority', data_type: 'STRING' },
                    { column_name: 'task_state', data_type: 'STRING' },
                    { column_name: 'asmtins_state', data_type: 'STRING' }
                ],
                tableName: this.config.sourceTable,
                note: 'Cross-project schema limitations'
            };
        }
    }

    /**
     * Get sample data from source table
     */
    async getSampleData(limit = 3) {
        try {
            console.log(`üìã Getting sample data (${limit} records)...`);
            
            const sampleQuery = `
                SELECT task_sys_id, task_number, task_priority, task_state, asmtins_state, task_sys_created_on
                FROM \`${this.config.sourceTable}\`
                WHERE task_sys_id IS NOT NULL
                ORDER BY task_sys_created_on DESC
                LIMIT ${limit}
            `;
            
            const [sampleResults] = await this.bigquery.query(sampleQuery);
            
            console.log(`‚úÖ Sample data retrieved: ${sampleResults.length} records`);
            
            return {
                success: true,
                message: 'Sample data retrieved',
                sampleCount: sampleResults.length,
                sampleData: sampleResults,
                tableName: this.config.sourceTable
            };
            
        } catch (error) {
            console.error('‚ùå Sample data retrieval failed:', error.message);
            throw new Error(`Failed to get sample data: ${error.message}`);
        }
    }

    /**
     * Initialize temp dataset for validation tables
     */
    async initializeTempDataset() {
        try {
            console.log(`üîß Initializing temp dataset: ${this.config.tempDataset}`);
            
            const dataset = this.bigquery.dataset(this.config.tempDataset);
            const [exists] = await dataset.exists();
            
            if (!exists) {
                console.log(`üìÅ Creating dataset: ${this.config.tempDataset}`);
                await dataset.create({
                    description: 'Temporary tables for JSON vs BigQuery validation',
                    location: 'US',
                    defaultTableExpirationMs: String(24 * 60 * 60 * 1000) // 24 hours
                });
                console.log(`‚úÖ Dataset created: ${this.config.tempDataset}`);
            } else {
                console.log(`‚úÖ Dataset already exists: ${this.config.tempDataset}`);
            }
            
            return {
                success: true,
                message: 'Temp dataset ready',
                datasetId: this.config.tempDataset
            };
            
        } catch (error) {
            console.error('‚ùå Failed to initialize temp dataset:', error.message);
            throw new Error(`Dataset initialization failed: ${error.message}`);
        }
    }

    /**
     * üîß UPDATED: Create temp table with FALLBACK CLEANUP STRATEGY
     */
    async createTempTableFromJSON(jsonData, tableId) {
        try {
            console.log(`üîß UPDATED: Creating temp table with FALLBACK CLEANUP STRATEGY`);
            console.log(`üìä Input verification: ${jsonData.length} records to process`);
            
            // CRITICAL: Verify input data integrity first
            const inputTaskSysIds = jsonData.map(r => r.task_sys_id).filter(id => id);
            const uniqueInputIds = [...new Set(inputTaskSysIds)];
            
            console.log(`üîç INPUT VERIFICATION:`);
            console.log(`   üìä Total input records: ${jsonData.length}`);
            console.log(`   üîë Records with task_sys_id: ${inputTaskSysIds.length}`);
            console.log(`   ‚ú® Unique task_sys_id values: ${uniqueInputIds.length}`);
            console.log(`   üìã Unique IDs: [${uniqueInputIds.join(', ')}]`);
            
            // First ensure temp dataset exists
            await this.initializeTempDataset();
            
            // üîß FALLBACK STRATEGY: Generate timestamped table name to avoid conflicts
            const timestamp = Date.now();
            const randomSuffix = Math.floor(Math.random() * 1000);
            const tempTableName = `${this.config.tempTablePrefix}${tableId}_${timestamp}_${randomSuffix}`;
            const fullTableId = `${process.env.GOOGLE_CLOUD_PROJECT_ID}.${this.config.tempDataset}.${tempTableName}`;
            
            console.log(`üéØ FALLBACK: Using timestamped temp table: ${fullTableId}`);
            
            // Get dataset and table references
            const dataset = this.bigquery.dataset(this.config.tempDataset);
            const table = dataset.table(tempTableName);
            
            // üîß FALLBACK CLEANUP STRATEGY: Try to clean old tables but don't fail if it doesn't work
            console.log(`üîç FALLBACK CLEANUP: Attempting to clean old tables (non-blocking)...`);
            
            try {
                // Try to clean up old tables with same fileId (without timestamp)
                const oldTempTableName = `${this.config.tempTablePrefix}${tableId}`;
                const oldTable = dataset.table(oldTempTableName);
                
                console.log(`üóëÔ∏è Attempting cleanup of old table: ${oldTempTableName}`);
                
                try {
                    const [oldExists] = await oldTable.exists();
                    if (oldExists) {
                        console.log(`üßπ Found old table, attempting cleanup...`);
                        
                        // Try cleanup with timeout (non-blocking)
                        const cleanupPromise = oldTable.delete();
                        const timeoutPromise = new Promise((_, reject) => 
                            setTimeout(() => reject(new Error('Cleanup timeout')), 10000)
                        );
                        
                        try {
                            await Promise.race([cleanupPromise, timeoutPromise]);
                            console.log(`‚úÖ Old table cleanup successful`);
                            await new Promise(resolve => setTimeout(resolve, 2000));
                        } catch (cleanupError) {
                            console.warn(`‚ö†Ô∏è Old table cleanup failed (proceeding with timestamped table): ${cleanupError.message}`);
                        }
                    } else {
                        console.log(`‚úÖ No old table found - proceeding with fresh creation`);
                    }
                } catch (oldCheckError) {
                    console.warn(`‚ö†Ô∏è Old table check failed (proceeding anyway): ${oldCheckError.message}`);
                }
                
            } catch (cleanupError) {
                console.warn(`‚ö†Ô∏è Fallback cleanup failed (using timestamped table anyway): ${cleanupError.message}`);
            }
            
            // Ensure our new timestamped table doesn't exist (it shouldn't)
            try {
                const [newTableExists] = await table.exists();
                if (newTableExists) {
                    console.warn(`‚ö†Ô∏è Timestamped table unexpectedly exists, generating new timestamp`);
                    const newTimestamp = Date.now() + Math.floor(Math.random() * 10000);
                    const finalTempTableName = `${this.config.tempTablePrefix}${tableId}_${newTimestamp}`;
                    const finalFullTableId = `${process.env.GOOGLE_CLOUD_PROJECT_ID}.${this.config.tempDataset}.${finalTempTableName}`;
                    
                    // Update references
                    const finalTable = dataset.table(finalTempTableName);
                    console.log(`üÜï Using final table name: ${finalFullTableId}`);
                    
                    // Update variables for the rest of the function
                    tempTableName = finalTempTableName;
                    fullTableId = finalFullTableId;
                    table = finalTable;
                }
            } catch (newCheckError) {
                console.log(`‚úÖ New table check passed (expected to not exist)`);
            }

            // Process data with complete flattening
            console.log(`üßπ Processing data with complete field flattening...`);
            
            const processedData = jsonData.map((record, index) => {
                const processed = {};
                
                // Flatten ALL nested objects properly  
                const flattenObject = (obj, prefix = '') => {
                    for (const [key, value] of Object.entries(obj)) {
                        const cleanKey = this.cleanFieldName(prefix ? `${prefix}_${key}` : key);
                        
                        if (value !== null && typeof value === 'object' && !Array.isArray(value)) {
                            // Handle ServiceNow reference objects
                            if (value.display_value !== undefined || value.link !== undefined || value.value !== undefined) {
                                // ServiceNow reference object - create separate fields
                                if (value.display_value !== undefined && value.display_value !== null) {
                                    processed[`${cleanKey}_display_value`] = this.cleanDataValue(value.display_value, `${cleanKey}_display_value`);
                                }
                                if (value.link !== undefined && value.link !== null) {
                                    processed[`${cleanKey}_link`] = this.cleanDataValue(value.link, `${cleanKey}_link`);
                                }
                                if (value.value !== undefined && value.value !== null) {
                                    processed[`${cleanKey}_value`] = this.cleanDataValue(value.value, `${cleanKey}_value`);
                                }
                            } else {
                                // Regular nested object - flatten recursively (limited depth)
                                if (prefix.split('_').length < 2) {
                                    flattenObject(value, cleanKey);
                                } else {
                                    processed[cleanKey] = this.cleanDataValue(JSON.stringify(value), cleanKey);
                                }
                            }
                        } else if (Array.isArray(value)) {
                            processed[cleanKey] = this.cleanDataValue(JSON.stringify(value), cleanKey);
                        } else {
                            processed[cleanKey] = this.cleanDataValue(value, cleanKey);
                        }
                    }
                };
                
                flattenObject(record);
                
                // Log first record for verification
                if (index === 0) {
                    console.log(`üîç Processing verification (first record):`);
                    console.log(`   üìã Original fields: ${Object.keys(record).length}`);
                    console.log(`   üßπ Processed fields: ${Object.keys(processed).length}`);
                    console.log(`   üîë task_sys_id: ${processed.task_sys_id || 'NOT FOUND'}`);
                }
                
                return processed;
            });
            
            console.log(`‚úÖ Data processing complete: ${processedData.length} records processed`);

            // Verify no records lost during processing
            if (processedData.length !== jsonData.length) {
                console.error(`‚ùå CRITICAL: Record count changed during processing! Input: ${jsonData.length}, Processed: ${processedData.length}`);
                throw new Error(`Processing error: Expected ${jsonData.length} records, got ${processedData.length}`);
            }

            // Generate schema from processed data
            console.log(`üîç Generating complete schema from processed data...`);
            const schema = this.generateCompleteSchemaFromProcessedData(processedData);
            console.log(`üìã Schema generated: ${schema.length} fields`);

            // Create fresh table
            console.log(`üîß Creating fresh timestamped temp table...`);
            
            await table.create({
                schema: schema,
                description: `Fresh temp table with fallback strategy - ${new Date().toISOString()}`,
                expirationTime: Date.now() + 24 * 60 * 60 * 1000 // 24 hours
            });
            console.log(`‚úÖ Fresh temp table created successfully`);
            
            // Extended wait for table initialization
            console.log(`‚è≥ Waiting 10 seconds for BigQuery to initialize the table...`);
            await new Promise(resolve => setTimeout(resolve, 10000));
            
            // SINGLE ATOMIC INSERTION (No Retries = No Duplication)
            console.log(`üì§ SINGLE ATOMIC INSERTION of exactly ${processedData.length} records...`);
            console.log(`üîí NO RETRY LOGIC - Single attempt only to prevent duplication`);
            
            // Prepare ultra-clean data for single insertion
            const insertionData = processedData.map((record, index) => {
                const cleanRecord = {};
                
                // Ensure all schema fields are present with safe values
                schema.forEach(field => {
                    const fieldName = field.name;
                    if (record.hasOwnProperty(fieldName)) {
                        const value = record[fieldName];
                        if (value === null || value === undefined || value === '') {
                            cleanRecord[fieldName] = null;
                        } else {
                            // Ultra-safe string conversion
                            cleanRecord[fieldName] = String(value)
                                .replace(/[^\x20-\x7E\s]/g, '') // Only printable ASCII + whitespace
                                .trim()
                                .substring(0, 10000) || null;
                        }
                    } else {
                        cleanRecord[fieldName] = null;
                    }
                });
                
                return cleanRecord;
            });
            
            // Final verification before insertion
            console.log(`üîç Pre-insertion verification:`);
            console.log(`   üìä Records prepared for insertion: ${insertionData.length}`);
            console.log(`   üîë First record task_sys_id: ${insertionData[0]?.task_sys_id}`);
            console.log(`   üîë Last record task_sys_id: ${insertionData[insertionData.length - 1]?.task_sys_id}`);
            console.log(`   üìÑ Fields per record: ${Object.keys(insertionData[0] || {}).length}`);
            
            // SINGLE ATOMIC INSERTION - THE KEY TO PREVENTING DUPLICATION
            try {
                const insertStartTime = Date.now();
                console.log(`üöÄ Starting SINGLE ATOMIC INSERT at ${new Date().toISOString()}`);
                
                await table.insert(insertionData);
                
                const insertDuration = Date.now() - insertStartTime;
                console.log(`‚úÖ SINGLE ATOMIC INSERT COMPLETED in ${insertDuration}ms`);
                console.log(`üîí ZERO DUPLICATION GUARANTEED: Exactly ${insertionData.length} records inserted ONCE`);
                
            } catch (insertError) {
                console.error(`‚ùå SINGLE ATOMIC INSERT FAILED:`, insertError.message);
                
                if (insertError.errors && insertError.errors.length > 0) {
                    console.error(`üîç First insertion error:`, insertError.errors[0]);
                    
                    // Log up to 3 errors for debugging
                    insertError.errors.slice(0, 3).forEach((err, idx) => {
                        console.error(`   Error ${idx + 1}:`, {
                            reason: err.reason,
                            message: err.message,
                            location: err.location,
                            row: err.row
                        });
                    });
                }
                
                throw new Error(`SINGLE ATOMIC INSERT FAILED: ${insertError.message}`);
            }
            
            // COMPREHENSIVE VERIFICATION
            console.log(`üîç COMPREHENSIVE VERIFICATION: Confirming exact record count...`);
            
            // Extended wait for BigQuery to process the insertion
            await new Promise(resolve => setTimeout(resolve, 6000));
            
            try {
                // Multiple verification queries
                const verificationQueries = [
                    {
                        name: 'Total Count',
                        query: `SELECT COUNT(*) as count FROM \`${fullTableId}\``
                    },
                    {
                        name: 'Unique task_sys_id Count',
                        query: `SELECT COUNT(DISTINCT task_sys_id) as count FROM \`${fullTableId}\``
                    },
                    {
                        name: 'Non-null task_sys_id Count',
                        query: `SELECT COUNT(*) as count FROM \`${fullTableId}\` WHERE task_sys_id IS NOT NULL`
                    },
                    {
                        name: 'task_sys_id Distribution',
                        query: `
                            SELECT 
                                task_sys_id, 
                                COUNT(*) as occurrence_count 
                            FROM \`${fullTableId}\` 
                            WHERE task_sys_id IS NOT NULL
                            GROUP BY task_sys_id 
                            ORDER BY occurrence_count DESC
                        `
                    }
                ];
                
                const verificationResults = {};
                
                for (const queryInfo of verificationQueries) {
                    try {
                        const [queryResult] = await this.bigquery.query(queryInfo.query);
                        verificationResults[queryInfo.name] = queryResult;
                        
                        if (queryInfo.name.includes('Count')) {
                            const count = queryResult[0]?.count || 0;
                            console.log(`‚úÖ ${queryInfo.name}: ${count}`);
                        } else if (queryInfo.name === 'task_sys_id Distribution') {
                            console.log(`‚úÖ ${queryInfo.name}:`, queryResult);
                        }
                    } catch (verifyError) {
                        console.error(`‚ùå Verification query '${queryInfo.name}' failed:`, verifyError.message);
                        verificationResults[queryInfo.name] = { error: verifyError.message };
                    }
                }
                
                // Extract verification results
                const finalCount = parseInt(verificationResults['Total Count'][0]?.count || 0);
                const uniqueCount = parseInt(verificationResults['Unique task_sys_id Count'][0]?.count || 0);
                const nonNullCount = parseInt(verificationResults['Non-null task_sys_id Count'][0]?.count || 0);
                const distribution = verificationResults['task_sys_id Distribution'] || [];
                
                // COMPREHENSIVE VERIFICATION ANALYSIS
                console.log(`üìä COMPREHENSIVE VERIFICATION RESULTS:`);
                console.log(`   üì• Original JSON records: ${jsonData.length}`);
                console.log(`   üì§ Records in temp table: ${finalCount}`);
                console.log(`   üîë Unique task_sys_id values: ${uniqueCount}`);
                console.log(`   ‚úÖ Expected unique values: ${uniqueInputIds.length}`);
                console.log(`   üìã task_sys_id distribution:`, distribution);
                
                // CRITICAL VERIFICATION CHECKS
                const verificationPassed = {
                    exactRecordCount: finalCount === jsonData.length,
                    exactUniqueCount: uniqueCount === uniqueInputIds.length,
                    noRecordLoss: finalCount > 0,
                    noDuplication: finalCount <= jsonData.length
                };
                
                console.log(`üîç VERIFICATION STATUS:`, verificationPassed);
                
                // ERROR CONDITIONS
                if (finalCount === 0) {
                    console.error(`‚ùå CRITICAL ERROR: No records found in temp table!`);
                    throw new Error('ZERO RECORDS: No records were successfully inserted into temp table');
                }
                
                if (finalCount > jsonData.length) {
                    console.error(`‚ùå DUPLICATION DETECTED: Expected ${jsonData.length}, found ${finalCount}`);
                    console.error(`üîç Duplication details:`, distribution);
                    throw new Error(`DUPLICATION ERROR: Expected ${jsonData.length} records, found ${finalCount} (duplication occurred)`);
                }
                
                if (finalCount < jsonData.length) {
                    console.warn(`‚ö†Ô∏è RECORD LOSS: Expected ${jsonData.length}, found ${finalCount}`);
                    console.warn(`üìä Loss ratio: ${((jsonData.length - finalCount) / jsonData.length * 100).toFixed(1)}%`);
                }
                
                // SUCCESS CONDITIONS
                if (finalCount === jsonData.length) {
                    console.log(`‚úÖ PERFECT SUCCESS: Exact record count match (${finalCount} records)`);
                }
                
                if (uniqueCount === uniqueInputIds.length) {
                    console.log(`‚úÖ PERFECT SUCCESS: Exact unique count match (${uniqueCount} unique IDs)`);
                }
                
                return {
                    success: true,
                    message: 'FALLBACK SUCCESS: Temp table created with ZERO DUPLICATION using fallback strategy',
                    tempTableId: fullTableId,
                    tempTableName: tempTableName,
                    inputRecords: jsonData.length,
                    recordsInTable: finalCount,
                    uniqueIdsInput: uniqueInputIds.length,
                    uniqueIdsInTable: uniqueCount,
                    recordCountMatch: finalCount === jsonData.length,
                    uniqueCountMatch: uniqueCount === uniqueInputIds.length,
                    distributionAnalysis: distribution,
                    verification: verificationResults,
                    fieldsProcessed: schema.length,
                    approach: 'fallback-timestamped-single-atomic-insert',
                    guarantees: [
                        'Timestamped table names prevent conflicts',
                        'Non-blocking cleanup preserves functionality',
                        'Single atomic insertion prevents duplication',
                        'Comprehensive verification ensures accuracy'
                    ],
                    expiresAt: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString()
                };
                
            } catch (verifyError) {
                console.error(`‚ùå Comprehensive verification failed:`, verifyError.message);
                throw new Error(`Verification failed: ${verifyError.message}`);
            }
            
        } catch (error) {
            console.error('‚ùå Fallback temp table creation failed:', error.message);
            throw new Error(`Fallback temp table creation failed: ${error.message}`);
        }
    }

    /**
     * Generate schema from ALL processed data fields
     */
    generateCompleteSchemaFromProcessedData(processedData) {
        const allFields = new Set();
        
        // Analyze all records to get complete field list
        processedData.forEach((record, index) => {
            Object.keys(record).forEach(key => {
                allFields.add(key);
            });
        });
        
        // Generate schema for ALL fields (conservative STRING type for safety)
        const schema = Array.from(allFields).sort().map(fieldName => {
            return {
                name: fieldName,
                type: 'STRING', // Use STRING for everything to avoid type issues
                mode: 'NULLABLE'
            };
        });
        
        console.log(`‚úÖ Complete schema: ${schema.length} fields from ALL original data`);
        console.log(`üîë Key fields:`, schema.filter(f => 
            ['task_sys_id', 'task_number', 'task_priority', 'task_state', 'asmtins_state'].includes(f.name)
        ).map(f => f.name));
        
        return schema;
    }

    /**
     * Generate complete schema from ALL records (ENHANCED VERSION)
     */
    generateCompleteSchemaFromAllRecords(jsonData) {
        const allFields = new Set();
        const fieldTypes = {};
        
        const sampleSize = Math.min(1000, jsonData.length);
        const recordsToAnalyze = jsonData.slice(0, sampleSize);
        
        console.log(`üîç Analyzing ${recordsToAnalyze.length} records for complete schema...`);
        
        recordsToAnalyze.forEach((record, index) => {
            if (index % 100 === 0 && index > 0) {
                console.log(`   üìã Analyzed ${index}/${recordsToAnalyze.length} records...`);
            }
            
            for (const [key, value] of Object.entries(record)) {
                allFields.add(key);
                
                if (value !== null && value !== undefined && !fieldTypes[key]) {
                    if (typeof value === 'boolean') {
                        fieldTypes[key] = 'BOOLEAN';
                    } else if (typeof value === 'number') {
                        fieldTypes[key] = Number.isInteger(value) ? 'INTEGER' : 'FLOAT';
                    } else if (typeof value === 'string') {
                        if (value.match(/^\d{4}-\d{2}-\d{2}[\sT]\d{2}:\d{2}:\d{2}$/) && value.length <= 25) {
                            fieldTypes[key] = 'TIMESTAMP';
                        } else {
                            fieldTypes[key] = 'STRING';
                        }
                    } else {
                        fieldTypes[key] = 'STRING';
                    }
                }
            }
        });
        
        const schema = Array.from(allFields).sort().map(fieldName => {
            let fieldType = fieldTypes[fieldName] || 'STRING';
            
            // Force problematic fields to STRING
            const forceStringFields = [
                'task_comments', 
                'task_u_comments_and_work_notes', 
                'task_u_comment_list',
                'task_description',
                'asmttype_description',
                'metricres_string_value'
            ];
            
            if (forceStringFields.some(field => fieldName.includes(field))) {
                fieldType = 'STRING';
            }
            
            return {
                name: fieldName,
                type: fieldType,
                mode: 'NULLABLE'
            };
        });
        
        console.log(`‚úÖ Complete schema analysis: ${allFields.size} fields found`);
        
        return schema;
    }

    /**
     * Generate BigQuery schema from JSON object (LEGACY)
     */
    generateSchemaFromJSON(jsonObject) {
        const schema = [];
        
        for (const [key, value] of Object.entries(jsonObject)) {
            let fieldType = 'STRING';
            
            if (value === null || value === undefined) {
                fieldType = 'STRING';
            } else if (typeof value === 'boolean') {
                fieldType = 'BOOLEAN';
            } else if (typeof value === 'number') {
                fieldType = Number.isInteger(value) ? 'INTEGER' : 'FLOAT';
            } else if (typeof value === 'string') {
                if (value.match(/^\d{4}-\d{2}-\d{2}[\sT]\d{2}:\d{2}:\d{2}$/) && value.length <= 25) {
                    fieldType = 'TIMESTAMP';
                } else {
                    fieldType = 'STRING';
                }
            } else if (typeof value === 'object' && value !== null) {
                fieldType = 'STRING';
            }
            
            schema.push({
                name: key,
                type: fieldType,
                mode: 'NULLABLE'
            });
        }
        
        console.log(`üìã Schema generated: ${schema.length} fields`);
        return schema;
    }

    /**
     * Clean up temp tables
     */
    async cleanupTempTable(tempTableName) {
        try {
            console.log(`üóëÔ∏è Cleaning up temp table: ${tempTableName}`);
            
            const dataset = this.bigquery.dataset(this.config.tempDataset);
            const table = dataset.table(tempTableName);
            
            const [exists] = await table.exists();
            if (exists) {
                await table.delete();
                console.log(`‚úÖ Temp table deleted: ${tempTableName}`);
                return { success: true, message: 'Temp table cleaned up' };
            } else {
                console.log(`‚ÑπÔ∏è Temp table not found: ${tempTableName}`);
                return { success: true, message: 'Temp table not found (may have expired)' };
            }
            
        } catch (error) {
            console.error('‚ùå Failed to cleanup temp table:', error.message);
            throw new Error(`Cleanup failed: ${error.message}`);
        }
    }
}

module.exports = BigQueryIntegrationService;